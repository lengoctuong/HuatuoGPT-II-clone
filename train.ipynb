{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af99266c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Non-empty input] ID: 10_Huatuo26M_chinese/huatuo_knowledge_graph_qa/train_datasets.json---5756, input: Kh√¥ng c√≥ ƒë·∫ßu v√†o\n",
      "[Non-empty input] ID: 10_Huatuo26M_chinese/huatuo_knowledge_graph_qa/train_datasets.json---9405, input: Kh√¥ng c√≥ ƒë·∫ßu v√†o.\n",
      "[Non-empty input] ID: 10_Huatuo26M_chinese/huatuo_knowledge_graph_qa/train_datasets.json---170700, input: Kh√¥ng c√≥ ƒë·∫ßu v√†o.\n",
      "[Non-empty input] ID: 10_Huatuo26M_chinese/huatuo_knowledge_graph_qa/train_datasets.json---270713, input: Kh√¥ng c√≥ ƒë·∫ßu v√†o\n",
      "[Non-empty input] ID: 10_Huatuo26M_chinese/huatuo_knowledge_graph_qa/train_datasets.json---290432, input: Kh√¥ng c√≥ ƒë·∫ßu v√†o\n",
      "[Non-empty input] ID: 10_Huatuo26M_chinese/huatuo_knowledge_graph_qa/train_datasets.json---310735, input: Kh√¥ng c√≥ ƒë·∫ßu v√†o.\n",
      "[Non-empty input] ID: 10_Huatuo26M_chinese/huatuo_knowledge_graph_qa/train_datasets.json---315893, input: Kh√¥ng c√≥ ƒë·∫ßu v√†o\n",
      "[Non-empty input] ID: 10_Huatuo26M_chinese/huatuo_knowledge_graph_qa/train_datasets.json---324454, input: Kh√¥ng c√≥ ƒë·∫ßu v√†o.\n",
      "[Non-empty input] ID: 10_Huatuo26M_chinese/huatuo_knowledge_graph_qa/train_datasets.json---376583, input: Kh√¥ng c√≥ ƒë·∫ßu v√†o.\n",
      "[Non-empty input] ID: 10_Huatuo26M_chinese/huatuo_knowledge_graph_qa/train_datasets.json---403669, input: Kh√¥ng c√≥ ƒë·∫ßu v√†o.\n",
      "[Non-empty input] ID: 10_Huatuo26M_chinese/huatuo_knowledge_graph_qa/train_datasets.json---415500, input: Kh√¥ng c√≥ ƒë·∫ßu v√†o.\n",
      "[Non-empty input] ID: 10_Huatuo26M_chinese/huatuo_knowledge_graph_qa/train_datasets.json---416929, input: Kh√¥ng c√≥ ƒë·∫ßu v√†o.\n",
      "[Non-empty input] ID: 10_Huatuo26M_chinese/huatuo_knowledge_graph_qa/train_datasets.json---466143, input: Kh√¥ng c√≥ ƒë·∫ßu v√†o.\n",
      "[Non-empty input] ID: 10_Huatuo26M_chinese/huatuo_knowledge_graph_qa/train_datasets.json---579870, input: Kh√¥ng c√≥ ƒë·∫ßu v√†o.\n",
      "[Non-empty input] ID: 10_Huatuo26M_chinese/huatuo_knowledge_graph_qa/train_datasets.json---582544, input: Kh√¥ng c√≥ ƒë·∫ßu v√†o.\n",
      "[Non-empty input] ID: 10_Huatuo26M_chinese/huatuo_knowledge_graph_qa/train_datasets.json---605479, input: -\n",
      "[Non-empty input] ID: 10_Huatuo26M_chinese/huatuo_knowledge_graph_qa/train_datasets.json---672386, input: B·ªánh bao g·ªìm b·ªánh l√Ω do virus CMV b·∫©m sinh.\n",
      "\n",
      "‚úÖ ƒê√£ x·ª≠ l√Ω 57080 m·∫´u. L∆∞u v√†o 'formatted_sft_data.json'\n"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "\n",
    "input_file = \"/mnt/c/Users/HOME/Downloads/HuatuoGPT-II/all_data/huatuo26m_vi.jsonl\"  # Thay b·∫±ng ƒë∆∞·ªùng d·∫´n file th·∫≠t\n",
    "output_data = []\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line)\n",
    "        instruction = item.get(\"instruction\", \"\").strip()\n",
    "        input_field = item.get(\"input\", \"\").strip()\n",
    "        output = item.get(\"output\", \"\").strip()\n",
    "\n",
    "        # In ra n·∫øu input kh√°c r·ªóng\n",
    "        if input_field:\n",
    "            print(f\"[Non-empty input] ID: {item.get('id')}, input: {input_field}\")\n",
    "\n",
    "        # G·ªôp input v√†o instruction n·∫øu c√≥\n",
    "        if input_field:\n",
    "            full_instruction = f\"{instruction}\\n\\n{input_field}\"\n",
    "        else:\n",
    "            full_instruction = instruction\n",
    "\n",
    "        # Th√™m v√†o d·∫°ng multi-turn [\"q\", \"a\"]\n",
    "        output_data.append([full_instruction, output])\n",
    "\n",
    "# Chuy·ªÉn th√†nh ƒë·ªãnh d·∫°ng m√† HuatuoGPT_data c√≥ th·ªÉ ƒë·ªçc:\n",
    "formatted_data = [qa_pair for qa_pair in output_data]  # m·ªói ph·∫ßn t·ª≠ l√† [\"question\", \"answer\"]\n",
    "\n",
    "# L∆∞u ra file n·∫øu mu·ªën:\n",
    "with open(os.path.join(os.path.dirname(input_file), \"train_\" + os.path.basename(input_file)[:-1]), \"w\", encoding=\"utf-8\") as out_f:\n",
    "    json.dump({\"SFT_data\": output_data}, out_f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ ƒê√£ x·ª≠ l√Ω {len(output_data)} m·∫´u. L∆∞u v√†o 'formatted_sft_data.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9809cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Non-empty input] ID: 11_HuatuoGPT2_chinese/HuatuoGPT2_Pretrain_Meidcal_Encyclopedia_en.json---5033, input: Kh√¥ng c√≥\n",
      "[Non-empty input] ID: 11_HuatuoGPT2_chinese/HuatuoGPT2_Pretrain_Meidcal_Encyclopedia_en.json---17979, input: Kh√¥ng c√≥ ƒë·∫ßu v√†o.\n",
      "[Non-empty input] ID: 11_HuatuoGPT2_chinese/HuatuoGPT2_Pretrain_Meidcal_Encyclopedia_en.json---62912, input: Kh√¥ng c√≥ ƒë·∫ßu v√†o.\n",
      "[Non-empty input] ID: 11_HuatuoGPT2_chinese/HuatuoGPT2_Pretrain_Meidcal_Encyclopedia_en.json---109450, input: Kh√¥ng c√≥ ƒë·∫ßu v√†o\n",
      "[Non-empty input] ID: 11_HuatuoGPT2_chinese/HuatuoGPT2_Pretrain_Meidcal_Encyclopedia_en.json---111084, input: Kh√¥ng c√≥ ƒë·∫ßu v√†o.\n",
      "[Non-empty input] ID: 11_HuatuoGPT2_chinese/HuatuoGPT2_Pretrain_Meidcal_Encyclopedia_en.json---114759, input: Kh√¥ng c√≥ ƒë·∫ßu v√†o.\n",
      "[Non-empty input] ID: 11_HuatuoGPT2_chinese/HuatuoGPT2_Pretrain_Meidcal_Encyclopedia_cn.json---58708, input: What are the effects and functions of Pediatric Clear Heat Cough Relief Oral Liquid?\n",
      "\n",
      "‚úÖ ƒê√£ x·ª≠ l√Ω 65765 m·∫´u. L∆∞u v√†o 'formatted_sft_data.json'\n"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "from collections import defaultdict\n",
    "\n",
    "# C√°c nh√£n thu·ªôc pretraining corpus\n",
    "pretrain_tags = {\n",
    "    \"Meidcal_Web_Corpus_en\",\n",
    "    \"Meidcal_Web_Corpus_cn\",\n",
    "    \"Meidcal_Literature_cn\",\n",
    "    \"Meidcal_Literature_en\",\n",
    "    \"Meidcal_Encyclopedia_cn\",\n",
    "    \"Meidcal_Encyclopedia_en\",\n",
    "    \"Meidcal_Books_cn\",\n",
    "    \"Meidcal_Books_en\",\n",
    "    \"SFT_data\"\n",
    "}\n",
    "\n",
    "def extract_tag_from_id(id_str):\n",
    "    # V√≠ d·ª•: \"11_HuatuoGPT2_chinese/HuatuoGPT2_Pretrain_Meidcal_Encyclopedia_en.json---15\"\n",
    "    for tag in pretrain_tags:\n",
    "        if tag in id_str:\n",
    "            return tag\n",
    "    return \"huatuo_knowledge_graph_qa\"\n",
    "\n",
    "def process_jsonl_file(file_path):\n",
    "    grouped_data = defaultdict(list)\n",
    "    \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            item = json.loads(line)\n",
    "            instruction = item.get(\"instruction\", \"\").strip()\n",
    "            output = item.get(\"output\", \"\").strip()\n",
    "            id_str = item.get(\"id\", \"\")\n",
    "\n",
    "            if not instruction or not output:\n",
    "                continue  # skip if missing q/a\n",
    "\n",
    "            tag = extract_tag_from_id(id_str)\n",
    "            grouped_data[tag].append([instruction, output])\n",
    "    \n",
    "    return grouped_data\n",
    "\n",
    "def merge_grouped_data(*grouped_dicts):\n",
    "    merged = defaultdict(list)\n",
    "    for d in grouped_dicts:\n",
    "        for k, v in d.items():\n",
    "            merged[k].extend(v)\n",
    "    return merged\n",
    "\n",
    "# === S·ª≠ d·ª•ng ===\n",
    "file1 = \"/mnt/c/Users/HOME/Downloads/HuatuoGPT-II/all_data/huatuo26m_vi.jsonl\"  # thay b·∫±ng t√™n file th·∫≠t\n",
    "file2 = \"/mnt/c/Users/HOME/Downloads/HuatuoGPT-II/all_data/huatuogpt2_vi.jsonl\"  # thay b·∫±ng t√™n file th·∫≠t\n",
    "input_file =   # Thay b·∫±ng ƒë∆∞·ªùng d·∫´n file th·∫≠t\n",
    "\n",
    "data1 = process_jsonl_file(file1)\n",
    "data2 = process_jsonl_file(file2)\n",
    "final_data = merge_grouped_data(data1, data2)\n",
    "\n",
    "# Ghi ra file .json theo format HuatuoGPT_data c·∫ßn\n",
    "with open(\"formatted_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"‚úÖ Done. Saved to formatted_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "420c5e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved merged dataset to /mnt/c/Users/HOME/Downloads/HuatuoGPT-II/all_data/train_qa_0.1p_vi.json\n",
      " - Meidcal_Encyclopedia_en: 65 samples\n",
      " - huatuo_knowledge_graph_qa: 57 samples\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "def convert_jsonl_to_huatuo_format(file1, file2, output_file, percent=1):\n",
    "    # C√°c lo·∫°i id h·ª£p l·ªá\n",
    "    known_types = [\n",
    "        \"Meidcal_Web_Corpus_en\", \"Meidcal_Web_Corpus_cn\",\n",
    "        \"Meidcal_Literature_cn\", \"Meidcal_Literature_en\",\n",
    "        \"Meidcal_Encyclopedia_cn\", \"Meidcal_Encyclopedia_en\",\n",
    "        \"Meidcal_Books_cn\", \"Meidcal_Books_en\",\n",
    "        \"SFT_data\"\n",
    "    ]\n",
    "\n",
    "    def load_jsonl(filepath):\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            return [json.loads(line.strip()) for line in f if line.strip()]\n",
    "\n",
    "    # Load d·ªØ li·ªáu\n",
    "    data1 = load_jsonl(file1)\n",
    "    data2 = load_jsonl(file2)\n",
    "\n",
    "    # C·∫Øt n%\n",
    "    n1 = int(len(data1) * percent)\n",
    "    n2 = int(len(data2) * percent)\n",
    "    data1 = data1[:n1]\n",
    "    data2 = data2[:n2]\n",
    "\n",
    "    # D·ªØ li·ªáu k·∫øt qu·∫£\n",
    "    merged_data = {}\n",
    "\n",
    "    # X·ª≠ l√Ω file1\n",
    "    for item in data1:\n",
    "        id_str = item.get(\"id\", \"\")\n",
    "        key = None\n",
    "        for k in known_types:\n",
    "            if k in id_str:\n",
    "                key = k\n",
    "                break\n",
    "        if not key:\n",
    "            key = \"huatuo_knowledge_graph_qa\"  # fallback (tr∆∞·ªùng h·ª£p sai)\n",
    "        q, a = item[\"instruction\"].strip(), item[\"output\"].strip()\n",
    "        if not q or not a:\n",
    "            continue\n",
    "        merged_data.setdefault(key, []).append([q, a])\n",
    "\n",
    "    # X·ª≠ l√Ω file2\n",
    "    for item in data2:\n",
    "        id_str = item.get(\"id\", \"\")\n",
    "        matched = any(k in id_str for k in known_types)\n",
    "        key = \"huatuo_knowledge_graph_qa\" if not matched else \"UNKNOWN_TYPE\"\n",
    "        if key == \"UNKNOWN_TYPE\":\n",
    "            print('UNKNOWN_TYPE', item)\n",
    "            continue  # skip b·∫•t th∆∞·ªùng\n",
    "\n",
    "        q, a = item[\"instruction\"].strip(), item[\"output\"].strip()\n",
    "        if not q or not a:\n",
    "            continue\n",
    "        merged_data.setdefault(key, []).append([q, a])\n",
    "\n",
    "    # Ghi k·∫øt qu·∫£\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(merged_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"‚úÖ Saved merged dataset to {output_file}\")\n",
    "    for key, items in merged_data.items():\n",
    "        print(f\" - {key}: {len(items)} samples\")\n",
    "\n",
    "# üîß V√≠ d·ª• c√°ch g·ªçi:\n",
    "p = 0.1/100\n",
    "file1 = \"/mnt/c/Users/HOME/Downloads/HuatuoGPT-II/all_data/huatuogpt2_vi.jsonl\"\n",
    "file2 = \"/mnt/c/Users/HOME/Downloads/HuatuoGPT-II/all_data/huatuo26m_vi.jsonl\"\n",
    "convert_jsonl_to_huatuo_format(\n",
    "    file1=file1,\n",
    "    file2=file2,\n",
    "    output_file=os.path.join(os.path.dirname(file1), \"train_qa_\" + str(p*100) + \"p_vi.json\"),\n",
    "    percent=p\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aede459e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
